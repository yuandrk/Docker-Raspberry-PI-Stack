
services:

  caddy:
    image: caddy:2.8-alpine
    container_name: caddy
    restart: unless-stopped
    environment:
      - CADDY_INGRESS_NETWORKS=internal
    ports:
      - "80:80"
      - "443:443"
    networks:
      - internal
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./Caddyfile:/etc/caddy/Caddyfile
      - ./caddy/data:/data
      - ./caddy/config:/config
    depends_on:
      - grafana
    

  grafana:
    container_name: monitoring-grafana
    image: grafana/grafana:latest
    hostname: rpi-grafana
    restart: unless-stopped
    user: "472"
    networks:
      - internal
    ports:
      - "3000:3000"
    env_file:
      - ./grafana/.env
    volumes:
      # /!\ To be modified depending on your needs /!\
      - ./grafana/data:/var/lib/grafana
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus

  cadvisor:
    container_name: monitoring-cadvisor
    image: gcr.io/cadvisor/cadvisor:v0.49.1
    hostname: rpi-cadvisor
    restart: unless-stopped
    privileged: true
    networks:
      - internal
    expose:
      - 8080
    command:
      - '-housekeeping_interval=15s'
      - '-docker_only=true'
      - '-store_container_labels=false'
    devices:
      - /dev/kmsg
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
      - /dev/disk/:/dev/disk:ro
      - /etc/machine-id:/etc/machine-id:ro
    depends_on:
      - redis
  
  redis:
    image: redis:latest
    container_name: redis
    restart: unless-stopped
    networks:
      - internal
    ports:
      - 6379:6379
    volumes:
      - ./redis/data:/data

  postgres:
    container_name: postgres
    image: postgres:latest
    hostname: rpi-postgres
    restart: unless-stopped
    networks:
      - internal
    env_file:
      - ./postgres.env
    ports:
      - "5432:5432"
    volumes:
      - ./postgres/data:/var/lib/postgresql/data

  node-exporter:
    container_name: monitoring-node-exporter
    image: prom/node-exporter:latest
    hostname: rpi-exporter
    restart: unless-stopped
    networks:
      - internal
    expose:
      - 9100
    command:
      - --path.procfs=/host/proc
      - --path.sysfs=/host/sys
      - --path.rootfs=/host
      - --collector.filesystem.ignored-mount-points
      - ^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
      - /:/host:ro,rslave

  prometheus:
    container_name: monitoring-prometheus
    image: prom/prometheus:latest
    hostname: rpi-prometheus
    restart: unless-stopped
    user: "nobody"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=1y'
      # /!\ Uncomment the following line to set a size limit for the Prometheus database /!\
#      - '--storage.tsdb.retention.size=10GB'
    networks:
      - internal
    expose:
      - 9090
    volumes:
      # /!\ To be modified depending on your needs /!\
      - ./prometheus/data:/prometheus
      - ./prometheus:/etc/prometheus/
    depends_on:
      - cadvisor
      - node-exporter
    links:
      - cadvisor:cadvisor
      - node-exporter:node-exporter

## OpenIA WebUI 
  chatgpt:
    image: ghcr.io/open-webui/open-webui:main
    container_name: chatgpt
    environment:
      - OPENAI_API_KEY=secrets
    ports:
      - "8080:8080"
    networks:
      - internal
    volumes:
      - /app/backend/data:/app/backend/data
    restart: always

networks:
  internal:
    driver: bridge
